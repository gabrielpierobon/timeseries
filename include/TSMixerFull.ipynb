{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb5e09d-4b55-4faf-99c7-f4fab72275f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29812bc9-be12-4009-825e-f3732364de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs.ts_forecasting import load_and_preprocess_data\n",
    "from libs.ts_forecasting import plot_loaded_data\n",
    "from libs.ts_forecasting import build_tsmixer_model\n",
    "from libs.ts_forecasting import train_tsmixer_model\n",
    "from libs.ts_forecasting import generate_dataset\n",
    "from libs.ts_forecasting import time_based_split\n",
    "from libs.ts_forecasting import scale_data\n",
    "from libs.ts_forecasting import inverse_transform_array\n",
    "from libs.ts_forecasting import train_test_time_based_split\n",
    "from libs.ts_forecasting import backtest_model\n",
    "from libs.ts_forecasting import predict_test_set\n",
    "from libs.ts_forecasting import forecast_data\n",
    "from libs.ts_forecasting import mean_absolute_percentage_error\n",
    "from libs.ts_forecasting import evaluate_test_set\n",
    "from libs.ts_forecasting import plot_test_set_predictions_with_history\n",
    "from libs.ts_forecasting import plot_future_forecast_with_history\n",
    "from libs.ts_forecasting import log_experiment_to_mlflow\n",
    "from libs.ts_forecasting import load_mlflow_experimental_model\n",
    "from libs.ts_forecasting import load_mlflow_staged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f556682",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 17:32:01.792841: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-07 17:32:01.855869: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-07 17:32:01.855902: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-07 17:32:01.856162: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-07 17:32:01.900452: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-07 17:32:01.901325: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 17:32:02.598845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_fields.py:128: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/pydantic/_internal/_config.py:317: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# # Load Functions\n",
    "# from libs.ts_forecasting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3045cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general configurations\n",
    "with open('config/general_config.yaml', 'r') as file:\n",
    "    general_config = yaml.safe_load(file)\n",
    "\n",
    "# Load project-specific configurations\n",
    "with open('config/project_config.yaml', 'r') as file:\n",
    "    project_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d469cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"General Configurations Loaded:\\n\")\n",
    "print(general_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d18665",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nProject Level Configurations Loaded:\\n\")\n",
    "print(project_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be2816c",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to contain the datasets we load\n",
    "dataframe_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b2d60a",
   "metadata": {},
   "source": [
    "# Inflation\n",
    "\n",
    "https://es.tradingeconomics.com/argentina/inflation-cpi#calendar-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c8773e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'general_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_1 \u001b[38;5;241m=\u001b[39m load_and_preprocess_data(\u001b[43mgeneral_config\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv_paths\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m      2\u001b[0m                                   general_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m      3\u001b[0m                                   project_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myears\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m      4\u001b[0m                                   project_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoints_per_year\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m dataframe_list\u001b[38;5;241m.\u001b[39mappend(data_1)\n\u001b[1;32m      6\u001b[0m plot_loaded_data(data_1, general_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'general_config' is not defined"
     ]
    }
   ],
   "source": [
    "data_1 = load_and_preprocess_data(general_config['csv_paths'][0], \n",
    "                                  general_config['features'][0], \n",
    "                                  project_config['years'], \n",
    "                                  project_config['points_per_year'])\n",
    "dataframe_list.append(data_1)\n",
    "plot_loaded_data(data_1, general_config['features'][0], \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a27af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "source": [
    "# LELIQs\n",
    "\n",
    "https://www.estadisticasbcra.com/leliq#:~:text=%23%23%23%23%20%C3%9Altimo%0A%0A%23%23%23%2015084400%0A%0A2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = load_and_preprocess_data(general_config['csv_paths'][1], \n",
    "                                  general_config['features'][1], \n",
    "                                  project_config['years'], \n",
    "                                  project_config['points_per_year'])\n",
    "\n",
    "# Special pre processing for this data\n",
    "data_2[general_config['features'][1]] = (data_2[general_config['features'][1]] / 1e6).round(2)\n",
    "\n",
    "dataframe_list.append(data_2)\n",
    "plot_loaded_data(data_2, general_config['features'][1], \"Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data for model training\n",
    "combined_dataframe = pd.concat(dataframe_list, axis=1)\n",
    "data = combined_dataframe.copy()\n",
    "data.columns = general_config['features']\n",
    "\n",
    "# Keep a copy of the original data for later purposes\n",
    "data_original = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e89e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e119b988",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b577f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "data, data_scalers = scale_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0240e6d8",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Set Creation:\n",
    "X_train, X_test, Y_train, Y_test, X, Y = train_test_time_based_split(np.array(data), \n",
    "                                                                     general_config['look_back'], \n",
    "                                                                     general_config['train_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91612fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TSMixer-inspired model\n",
    "tsmixer_model = build_tsmixer_model(input_shape=(general_config['look_back'], \n",
    "                                                 len(general_config['features'])), \n",
    "                                    num_features=len(general_config['features']))\n",
    "tsmixer_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "tsmixer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee06466",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_tsmixer_model(tsmixer_model, X_train, Y_train, X_test, Y_test, \n",
    "                              epochs=general_config['epochs'], \n",
    "                              batch_size=general_config['batch_size'], \n",
    "                              patience=general_config['patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cf7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions over the test set\n",
    "Y_test_original, predictions_original, predictions = predict_test_set(tsmixer_model, X_test, Y_test, \n",
    "                                                                      data_scalers, general_config['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the test set predictions with the history of the time series\n",
    "plot_test_set_predictions_with_history(Y_train, Y_test, predictions, data_scalers, general_config['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for the Test Set:\n",
    "print(\"\\n[Test Set] Evaluation:\")\n",
    "test_set_metrics = evaluate_test_set(Y_test, predictions, data_scalers, general_config['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2663c59",
   "metadata": {},
   "source": [
    "# Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f6b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply backtesting\n",
    "predictions_bt, true_values_bt = backtest_model(tsmixer_model, X, Y, general_config['features'], data_scalers,\n",
    "                                                plot_results=True, epochs=general_config['epochs'], \n",
    "                                                batch_size=general_config['batch_size'],\n",
    "                                                patience=general_config['patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292474df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the evaluate function for backtesting results\n",
    "print(\"\\n[Backtest] Evaluation:\")\n",
    "metrics_bt = evaluate_test_set(true_values_bt, predictions_bt, data_scalers, general_config['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9eef9",
   "metadata": {},
   "source": [
    "# Future Forecast (beyond Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast with Production model:\n",
    "forecasted_col_names = [f\"forecasted_{feature}\" for feature in general_config['features']]\n",
    "forecasted_df = forecast_data(tsmixer_model, data, general_config['look_back'], 12, \n",
    "                              data_scalers, general_config['features'], columns=forecasted_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678116ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast with history\n",
    "history_and_forecast_df = pd.concat([data_original, forecasted_df], axis=0)\n",
    "plot_future_forecast_with_history(history_and_forecast_df, general_config['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7895d79",
   "metadata": {},
   "source": [
    "# MLFlow Experiment Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359fbb18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# MLFlow Experiment Registration and model saving\n",
    "\n",
    "# MLFlow Configuration\n",
    "metrics_to_log = {\n",
    "    \"Inflation - TestSet - MAE\": test_set_metrics['inflacion_MAE'],\n",
    "    \"LELIQs - TestSet - MAE\": test_set_metrics['leliqs_MAE'],\n",
    "    \"Inflation - TestSet - RMSE\": test_set_metrics['inflacion_RMSE'],\n",
    "    \"LELIQs - TestSet - RMSE\": test_set_metrics['leliqs_RMSE'],\n",
    "    \"Inflation - TestSet - MAPE\": test_set_metrics['inflacion_MAPE'],\n",
    "    \"LELIQs - TestSet - MAPE\": test_set_metrics['leliqs_MAPE'],\n",
    "    \"Inflation - Backtesting - MAE\": metrics_bt['inflacion_MAE'],\n",
    "    \"LELIQs - Backtesting - MAE\": metrics_bt['leliqs_MAE'],\n",
    "    \"Inflation - Backtesting - RMSE\": metrics_bt['inflacion_RMSE'],\n",
    "    \"LELIQs - Backtesting - RMSE\": metrics_bt['leliqs_RMSE'],\n",
    "    \"Inflation - Backtesting - MAPE\": metrics_bt['inflacion_MAPE'],\n",
    "    \"LELIQs - Backtesting - MAPE\": metrics_bt['leliqs_MAPE']\n",
    "}\n",
    "\n",
    "artifacts_to_log = [\"plots/training_loss_plot.png\", \n",
    "                    \"plots/test_set_predictions.png\", \n",
    "                    \"plots/backtesting_predictions.png\", \n",
    "                    \"plots/future_forecast.png\"]\n",
    "\n",
    "if general_config['register_experiment']:\n",
    "    log_experiment_to_mlflow(tsmixer_model, general_config['model_name'], \n",
    "                             general_config['experiment_version'], general_config['model_artifact_name'],\n",
    "                             general_config['epochs'], general_config['batch_size'], \n",
    "                             metrics_to_log, artifacts_to_log, history_and_forecast_df)\n",
    "    \n",
    "    print(\"Experiment Registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a904a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "source": [
    "# Loading Favorite Experiment Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e21e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading Favorite Experiment Model:\n",
    "# favorite_run_id = '06663277c6ba4300bbfd5803e1cca34e'\n",
    "# tsmixer_model = load_mlflow_experimental_model(favorite_run_id, general_config['model_artifact_name'])\n",
    "# print(tsmixer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fdd94",
   "metadata": {},
   "source": [
    "# Registering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bf4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "if general_config['register_model']:\n",
    "    mlflow.register_model(f\"runs:/{favorite_run_id}/{general_config['model_artifact_name']}\", \n",
    "                          f\"{general_config['model_name']}_v{general_config['production_version']}\")\n",
    "    print(\"Model Registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727558e",
   "metadata": {},
   "source": [
    "# Fetching the MLflow Model from the Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading Staged Model:\n",
    "\n",
    "# tsmixer_model = load_mlflow_staged_model(general_config['model_name'], \n",
    "#                                          general_config['production_version'], \n",
    "#                                          general_config['stage'])\n",
    "# print(tsmixer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67548c10",
   "metadata": {},
   "source": [
    "# Check Model with Forecast again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7b075",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Forecast with Production model:\n",
    "forecasted_col_names = [f\"forecasted_{feature}\" for feature in general_config['features']]\n",
    "forecasted_df = forecast_data(tsmixer_model, data, general_config['look_back'], 12, \n",
    "                              data_scalers, general_config['features'], columns= forecasted_col_names)\n",
    "\n",
    "# Plot the forecast with history\n",
    "history_and_forecast_df = pd.concat([data_original, forecasted_df], axis=0)\n",
    "plot_future_forecast_with_history(history_and_forecast_df, general_config['features'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
